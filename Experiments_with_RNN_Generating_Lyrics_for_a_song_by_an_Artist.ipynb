{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiments with RNN -- Generating Lyrics for a song by an Artist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datasigntist/deeplearning/blob/master/Experiments_with_RNN_Generating_Lyrics_for_a_song_by_an_Artist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erKp3CjawyR-",
        "colab_type": "text"
      },
      "source": [
        "# **Experiments with RNN -- Generating Lyrics for a song by an Artist**\n",
        "\n",
        "**Author**: Vishwanathan Raman\n",
        "**Email**: datasigntist@gmail.com\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Change History**\n",
        "\n",
        "\n",
        "*   9-Sep-2019 -- Initial Creation\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Credits**\n",
        "The code articulated here has been inspired from coursera deeplearning.ai Assignments\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Use Case Description**\n",
        "\n",
        "This notebook develops a Recurrent Neural Network to generate lyrics of song using a seed, based on the history of songs done by the artist Bruce Springsteen.\n",
        "\n",
        "The following is the source of the dataset https://www.kaggle.com/mousehead/songlyrics\n",
        "\n",
        "The following is the video articulating the concepts\n",
        "https://www.youtube.com/playlist?list=PLkEQhv7sdYRLeBn_a5EaXdLBPEp0zASsx\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Other Learning Resources**\n",
        "\n",
        "The following youtube playlist lists all the concepts related to Deep Learning \n",
        "\n",
        "\n",
        "*   https://www.youtube.com/watch?v=yEfsDHymL0w&list=PLZnyIsit9AM7yeTZuBmezKNc6hFHUPImh\n",
        "*   https://www.youtube.com/watch?v=YgpI2aROLlo&list=PLZnyIsit9AM7HBPn6m06ddzw_N9zGk--2\n",
        "*   https://www.youtube.com/watch?v=186rxP6qfJA&list=PLZnyIsit9AM7VI4ylALdbeS93i-nonUzZ\n",
        "\n",
        "**Articles on Embedding**\n",
        "*   https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDHWWgqLQs5X",
        "colab_type": "text"
      },
      "source": [
        "# **Tensorflow Installation (Optional)**\n",
        "\n",
        "This experiment is built on tensorflow 2.0 gpu, run a quick check to see the current version, if its not 2.0 then uninstall the current version and install the 2.0 gpu version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM7qdWdRTwqy",
        "colab_type": "code",
        "outputId": "ca9aaae0-4350-48d7-d740-d7169bd480d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNAvenXYLb20",
        "colab_type": "code",
        "outputId": "bc54f797-c7e8-43aa-84ba-a9905aaff34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.0rc3:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-1.15.0rc3.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.0rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuVJNSerLgb2",
        "colab_type": "code",
        "outputId": "715167bd-be49-451e-b77b-b269276e0039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 82kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.16.5)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 27.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0 (from tensorflow-gpu)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/00/5e6cdf86190a70d7382d320b2b04e4ff0f8191a37d90a422a2f8ff0705bb/tensorflow_estimator-2.0.0-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-estimator-2.0.0 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN2E5VTMU3Lg",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Libraries and setting Global Variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tjcFKtF40SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np \n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNePVL6TaBo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "artistName = \"Bruce Springsteen\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41RPdbbbQ4MB",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset**\n",
        "\n",
        "The dataset is sourced from https://www.kaggle.com/mousehead/songlyrics . Its a compilation of 57650 songs by various artists. As part of the experiment, we are going to pick an artist by name \"Bruce Springsteen\" (https://en.wikipedia.org/wiki/Bruce_Springsteen), crawl his songs, build a RNN model and generate new lyrics using a seed text if he were to sing a new song. I recently happened to watch the movie  \"Blended by the Light\" (https://en.wikipedia.org/wiki/Blinded_by_the_Light_(2019_film)) on netflix which has Bruce Springsteen play the insipration role. On a personal note I loved his rendering of \"Born In the USA\" so decided to pick the BOSS as the artist for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZWYlca0laeR",
        "colab_type": "code",
        "outputId": "3c060256-a3bd-4b61-e6c4-89651cb7c366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Downloading the data from github\n",
        "!wget --no-check-certificate \"https://github.com/datasigntist/datasetsForTraining/raw/master/songlyrics.zip\" -O \"/tmp/songlyrics.zip\"\n",
        "  \n",
        "local_zip = '/tmp/songlyrics.zip'\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-10 06:43:17--  https://github.com/datasigntist/datasetsForTraining/raw/master/songlyrics.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/datasigntist/datasetsForTraining/master/songlyrics.zip [following]\n",
            "--2019-10-10 06:43:17--  https://raw.githubusercontent.com/datasigntist/datasetsForTraining/master/songlyrics.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21988108 (21M) [application/zip]\n",
            "Saving to: ‘/tmp/songlyrics.zip’\n",
            "\n",
            "/tmp/songlyrics.zip 100%[===================>]  20.97M   102MB/s    in 0.2s    \n",
            "\n",
            "2019-10-10 06:43:18 (102 MB/s) - ‘/tmp/songlyrics.zip’ saved [21988108/21988108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Qnse81zV26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data file\n",
        "songdata = pd.read_csv('/tmp/songdata.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC_7WWXz1JB3",
        "colab_type": "code",
        "outputId": "a5973dc2-918f-4733-885b-177481c9ec34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Browse the data\n",
        "\n",
        "songdata.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Ahe's My Kind Of Girl</td>\n",
              "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
              "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Andante, Andante</td>\n",
              "      <td>/a/abba/andante+andante_20002708.html</td>\n",
              "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>As Good As New</td>\n",
              "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
              "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang</td>\n",
              "      <td>/a/abba/bang_20598415.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABBA</td>\n",
              "      <td>Bang-A-Boomerang</td>\n",
              "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
              "      <td>Making somebody happy is a question of give an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist  ...                                               text\n",
              "0   ABBA  ...  Look at her face, it's a wonderful face  \\nAnd...\n",
              "1   ABBA  ...  Take it easy with me, please  \\nTouch me gentl...\n",
              "2   ABBA  ...  I'll never know why I had to go  \\nWhy I had t...\n",
              "3   ABBA  ...  Making somebody happy is a question of give an...\n",
              "4   ABBA  ...  Making somebody happy is a question of give an...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE3heSfY1SOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter the dataset by all songs by Artist\n",
        "\n",
        "songsByArtist = songdata[songdata[\"artist\"]==artistName]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkK-V6uW3PRc",
        "colab_type": "code",
        "outputId": "9a201709-4647-4a4e-e6e3-be90a4856c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Browse the songs by Artist\n",
        "\n",
        "songsByArtist.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>artist</th>\n",
              "      <th>song</th>\n",
              "      <th>link</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002</th>\n",
              "      <td>Bruce Springsteen</td>\n",
              "      <td>30 Days Out</td>\n",
              "      <td>/b/bruce+springsteen/30+days+out_20025285.html</td>\n",
              "      <td>We fell in love and I made you the world  \\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>Bruce Springsteen</td>\n",
              "      <td>Action In The Streets</td>\n",
              "      <td>/b/bruce+springsteen/action+in+the+streets_200...</td>\n",
              "      <td>Well don't move  \\nWhy don't you listen to wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004</th>\n",
              "      <td>Bruce Springsteen</td>\n",
              "      <td>All I'm Thinkin' About</td>\n",
              "      <td>/b/bruce+springsteen/all+im+thinkin+about_1005...</td>\n",
              "      <td>Blind man wavin' by the side of the road  \\nI'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005</th>\n",
              "      <td>Bruce Springsteen</td>\n",
              "      <td>All Night Long</td>\n",
              "      <td>/b/bruce+springsteen/all+night+long_10052078.html</td>\n",
              "      <td>I was born saved in heaven  \\nIt was nothing l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006</th>\n",
              "      <td>Bruce Springsteen</td>\n",
              "      <td>All That Heaven Will Allow</td>\n",
              "      <td>/b/bruce+springsteen/all+that+heaven+will+allo...</td>\n",
              "      <td>I got a dollar in my pocket  \\nThere ain't a c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 artist  ...                                               text\n",
              "2002  Bruce Springsteen  ...  We fell in love and I made you the world  \\nI ...\n",
              "2003  Bruce Springsteen  ...  Well don't move  \\nWhy don't you listen to wha...\n",
              "2004  Bruce Springsteen  ...  Blind man wavin' by the side of the road  \\nI'...\n",
              "2005  Bruce Springsteen  ...  I was born saved in heaven  \\nIt was nothing l...\n",
              "2006  Bruce Springsteen  ...  I got a dollar in my pocket  \\nThere ain't a c...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4JEZT943UKT",
        "colab_type": "code",
        "outputId": "63148488-4108-4664-ff09-5ea15c200966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Browse the songs by Artist \n",
        "\n",
        "print(\"Total number of songs by \", artistName, \":\",songsByArtist.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of songs by  Bruce Springsteen : 175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPvFzKa7V99i",
        "colab_type": "text"
      },
      "source": [
        "## **Compile all the songs of Bruce Springsteen into 1 single list**\n",
        "\n",
        "Compile all the songs of Bruce Springsteen into 1 single list. In the process\n",
        "\n",
        "*   Get rid of words like [chorus:] that do not mean anything\n",
        "*   Strip the empty sapces, remove any empty lines and get rid of specical characters like \"(\" , \")\" , \"\\\", \"/\" , \".\", \",\",\":\"\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqebLr7RdPr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopWords = [\"(\",\")\",\"/\",\"\\\\\",\".\",\",\",\":\",'\"']\n",
        "wordsTobeRemoved = [\"[chorus:]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMDhxEEs3iSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the dataset\n",
        "\n",
        "databyArtist = \"\\n\".join(songsByArtist[\"text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rs0Qvee4-Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = databyArtist.lower().split(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRygz1bHCyry",
        "colab_type": "code",
        "outputId": "657798d3-6abc-4f6e-d37c-8e1276714699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "corpus[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we fell in love and i made you the world  ',\n",
              " \"i spent all my time tryin' to satisfy you, girl  \",\n",
              " \"just one thing that i can't figure out  \",\n",
              " 'closer i get, farther baby i am out  ',\n",
              " '  ',\n",
              " '30 days, 30 days out  ',\n",
              " \"well i'm six days runnin' but i'm 30 days out  \",\n",
              " '30 days, 30 days out  ',\n",
              " 'with every kiss you leave a little shadow of doubt  ',\n",
              " '  ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njcRZ5USehQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for loop in range(len(wordsTobeRemoved)):\n",
        "  corpus = [line.replace(wordsTobeRemoved[loop],\"\") for line in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUOhEZhce9cA",
        "colab_type": "code",
        "outputId": "a3df0932-f93e-42f4-f678-ce9a99c25dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for loop in range(len(stopWords)):\n",
        "  print(stopWords[loop])\n",
        "  corpus = [line.replace(stopWords[loop],\"\") for line in corpus]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\n",
            ")\n",
            "/\n",
            "\\\n",
            ".\n",
            ",\n",
            ":\n",
            "\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFhf9ZLWap-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [elem.strip() for elem in corpus if elem.strip()!=\"\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76H_nzqT7jjE",
        "colab_type": "code",
        "outputId": "e65fcb9a-6bb9-4dbb-8942-4d81765fc48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Total number of lines : \",len(corpus))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of lines :  5788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_unqwhVKXHIW",
        "colab_type": "text"
      },
      "source": [
        "# Processing the data using tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIuGzP6klLXn",
        "colab_type": "text"
      },
      "source": [
        "## **Applying Tokenizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAlQlZ3EYjIU",
        "colab_type": "text"
      },
      "source": [
        "The fit_on_text function takes the corpus as the input, breaks the corpus into invidual words and assigns an unique number to each of the words. OOV or Out of Vocabulary is assigned for missing words. For each line in the corpus tokenizer generate a sequence of numbers through texts_to_sequences. The number for a specific word reflects what was generated in the previous step through fit_on_texts. \n",
        "\n",
        "For example if the sentence was \"Shyam is a good boy\", the texts_to_sequences generates an equivalent sequence like \"1234 45 48 90 1220\".\n",
        "\n",
        "Here \n",
        "*   1234 is a representation for \"Shyam\"\n",
        "*   45 is a representation for \"is\"\n",
        "*   48 is a representation for \"a\"\n",
        "*   90 is a representation for \"good\"\n",
        "*   1220 is a representation for \"boy\"\n",
        "\n",
        "Each line in the corpus is processed to generate a sequence of numbers as explained above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd8ATfbH5tMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(oov_token=\"OOV\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgbpMQtz5vCz",
        "colab_type": "code",
        "outputId": "4d551b4e-cc09-4480-a7f4-936e2de3cf1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Total number of words\", total_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words 4221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3skHVqnr6IVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reverse the word index\n",
        "reverseWordIndex = {v: k for k, v in tokenizer.word_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMOYD-WRlC5m",
        "colab_type": "text"
      },
      "source": [
        "## **Generating n-gram sequence**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjd3PCiNYKGp",
        "colab_type": "text"
      },
      "source": [
        "In addition to the above step for each sequence, a ngram sequence is generated using the numbers, for instance\n",
        "\n",
        "*   Shyam is\n",
        "*   Shyam is a \n",
        "*   Shyam is a good \n",
        "*   Shyam is a good boy\n",
        "\n",
        "Here words are being used here for illustration purposes. Ideally the words are represented by numbers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5hnuu7177BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1,len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs5MWDzn-Dxb",
        "colab_type": "code",
        "outputId": "4cfc8008-6930-4fc1-8a0c-616371ff70a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Total number of generated sequences \",len(input_sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of generated sequences  37630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMoja6ff-JAq",
        "colab_type": "code",
        "outputId": "ce61159d-5565-4fcf-90af-c54130352f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_sequences[0:4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[27, 309], [27, 309, 8], [27, 309, 8, 37], [27, 309, 8, 37, 4]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0OFigOj-WMU",
        "colab_type": "code",
        "outputId": "b88d41e9-38ef-4570-9fd4-c461bbe6930b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(reverseWordIndex[27],' ',reverseWordIndex[309],' ',reverseWordIndex[8],' ',reverseWordIndex[37])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we   fell   in   love\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUkx1F3rlU8s",
        "colab_type": "text"
      },
      "source": [
        "## **Padding the Sequence to maximum length**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwpmY2cg-eE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_sequence = max([len(x) for x in input_sequences])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVSgEuNH-jxO",
        "colab_type": "code",
        "outputId": "715553b2-a86c-432e-d842-91a33a6968ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Maximum length of sequence is \", max_len_sequence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum length of sequence is  18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqvxYXT6c3xO",
        "colab_type": "text"
      },
      "source": [
        "The ngram sequence generated in the previous step is of differing lengths. In order to compile them as single matrix, its essential to pad them with 0s. The shape of the matrix is equated to the length of the maximum sequence. Lets take the previous example \n",
        "\n",
        "*   Shyam is\n",
        "*   Shyam is a \n",
        "*   Shyam is a good \n",
        "*   Shyam is a good boy\n",
        "\n",
        "Assuming thats the only line the max length is 5 words hence each entry is padded with 0 to fill in the remaining pieces\n",
        "\n",
        "*   **0 0 0** Shyam is\n",
        "*   **0 0** Shyam is a \n",
        "*   **0** Shyam is a good \n",
        "*   Shyam is a good boy\n",
        "\n",
        "As you can see all the sequences are padded to the same length. The words being used here is for illustration purposes. Ideally the words are represented by numbers as shown in the below step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbqFpzA9_EN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences,maxlen=max_len_sequence,padding=\"pre\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUYiUurI_bpK",
        "colab_type": "code",
        "outputId": "bda43950-9b58-45ba-dd6e-c9543e1beff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Get a glimpse of padded sequences\n",
        "print(input_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0 ...   0  27 309]\n",
            " [  0   0   0 ...  27 309   8]\n",
            " [  0   0   0 ... 309   8  37]\n",
            " ...\n",
            " [  0   0   0 ... 515  30   3]\n",
            " [  0   0   0 ...  30   3  36]\n",
            " [  0   0   0 ...   3  36 728]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFRcxYTjldpC",
        "colab_type": "text"
      },
      "source": [
        "## **Defining the input and the labels**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMIJ4FJ7fCgu",
        "colab_type": "text"
      },
      "source": [
        "Now that the sequences have been made uniform in length, its time to split the data into X and labels. Here the label is the last datapoint in the sequence and everything else is X.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6iQT9BT_dSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = input_sequences[:,:-1]\n",
        "labels = input_sequences[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODNyP9Kw_xhC",
        "colab_type": "code",
        "outputId": "fce1b16b-3dc1-4ea9-8ca5-10c86e26face",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# View the X\n",
        "print(xs)\n",
        "# View the labels\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0 ...   0   0  27]\n",
            " [  0   0   0 ...   0  27 309]\n",
            " [  0   0   0 ...  27 309   8]\n",
            " ...\n",
            " [  0   0   0 ...   3 515  30]\n",
            " [  0   0   0 ... 515  30   3]\n",
            " [  0   0   0 ...  30   3  36]]\n",
            "[309   8  37 ...   3  36 728]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81cj7dxzlqOq",
        "colab_type": "text"
      },
      "source": [
        "## **Converting the labels to one hot encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG2qCkSEh_U2",
        "colab_type": "text"
      },
      "source": [
        "The labels identified in the last step is converted to a one hot encoding through the function to_categorical. The length of the one hot encoding is equivalent to the total number of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2r_ZClG_3Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ys = tf.keras.utils.to_categorical(labels,num_classes=total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyr7MT35HxaU",
        "colab_type": "code",
        "outputId": "ac2e830d-3a9e-431c-f99d-b01b263de3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Print the one hot encoding\n",
        "print(ys)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yj--I85AcEx",
        "colab_type": "code",
        "outputId": "a2fad3e6-fba6-4a43-e28d-926f9094c7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.argmax(ys[0])\n",
        "print(ys[0][309])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QoX-nZtmIoK",
        "colab_type": "text"
      },
      "source": [
        "## **Building the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo99ovgkmSGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddingSize = 500\n",
        "nodeCount = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vyyOiCvH_oM",
        "colab_type": "code",
        "outputId": "ef532e41-5942-4bc6-9fb5-bfc69ea2a983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, embeddingSize, input_length=max_len_sequence-1))\n",
        "model.add(Bidirectional(LSTM(nodeCount, return_sequences = True)))\n",
        "model.add(Bidirectional(LSTM(nodeCount, return_sequences = True)))\n",
        "model.add(LSTM(nodeCount))\n",
        "model.add(Dense(total_words, activation='relu'))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 17, 500)           2110500   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 17, 300)           781200    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 17, 300)           541200    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 150)               270600    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4221)              637371    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4221)              17821062  \n",
            "=================================================================\n",
            "Total params: 22,161,933\n",
            "Trainable params: 22,161,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZTn63hjtWU4",
        "colab_type": "text"
      },
      "source": [
        "## **Embedding Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFlboCuEtcFq",
        "colab_type": "code",
        "outputId": "5706d707-1f4d-4183-e12a-2e9715e00258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4221, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRiw5YV4te3C",
        "colab_type": "code",
        "outputId": "ce761fb6-89c0-4dea-bcf3-f7d9f8e061e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "happy_key = word_index[\"happy\"]\n",
        "happy_word = reverseWordIndex[happy_key]\n",
        "print(\"Key for Happy is :\", happy_key)\n",
        "happy_embeddings = weights[happy_key]\n",
        "print('Embeddings for Happy is :-->\\n', happy_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key for Happy is : 287\n",
            "Embeddings for Happy is :-->\n",
            " (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4uy2qXFuGGd",
        "colab_type": "code",
        "outputId": "d25d5daf-3321-44be-f55c-b909558ea3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "glad_key = word_index[\"glad\"]\n",
        "glad_word = reverseWordIndex[glad_key]\n",
        "print(\"Key for Glad is :\", glad_key)\n",
        "glad_embeddings = weights[glad_key]\n",
        "print('Embeddings for Glad is :-->\\n', glad_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key for Glad is : 1569\n",
            "Embeddings for Glad is :-->\n",
            " (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhze-C5IuOYL",
        "colab_type": "code",
        "outputId": "2a1ea738-d0dc-4130-fde5-1e4a5a67fb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "sad_key = word_index[\"sad\"]\n",
        "sad_word = reverseWordIndex[sad_key]\n",
        "print(\"Key for sad is :\", sad_key)\n",
        "sad_embeddings = weights[sad_key]\n",
        "print('Embeddings for sad is :-->\\n', sad_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key for sad is : 487\n",
            "Embeddings for sad is :-->\n",
            " (500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6kfudVcGtwd",
        "colab_type": "text"
      },
      "source": [
        "## **Training, Accuracy and Loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb_tPYljJD8c",
        "colab_type": "code",
        "outputId": "6e685268-7ac0-4d71-b768-712569333933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        " history = model.fit(xs, ys, epochs=100, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 37630 samples\n",
            "Epoch 1/25\n",
            "37630/37630 [==============================] - 97s 3ms/sample - loss: 0.6116 - accuracy: 0.8216\n",
            "Epoch 2/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6263 - accuracy: 0.8188\n",
            "Epoch 3/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6006 - accuracy: 0.8251\n",
            "Epoch 4/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6012 - accuracy: 0.8254\n",
            "Epoch 5/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6071 - accuracy: 0.8228\n",
            "Epoch 6/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6116 - accuracy: 0.8232\n",
            "Epoch 7/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6060 - accuracy: 0.8235\n",
            "Epoch 8/25\n",
            "37630/37630 [==============================] - 99s 3ms/sample - loss: 0.6028 - accuracy: 0.8242\n",
            "Epoch 9/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6079 - accuracy: 0.8226\n",
            "Epoch 10/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5942 - accuracy: 0.8265\n",
            "Epoch 11/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6052 - accuracy: 0.8235\n",
            "Epoch 12/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6108 - accuracy: 0.8222\n",
            "Epoch 13/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5964 - accuracy: 0.8250\n",
            "Epoch 14/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5898 - accuracy: 0.8271\n",
            "Epoch 15/25\n",
            "37630/37630 [==============================] - 99s 3ms/sample - loss: 0.6082 - accuracy: 0.8228\n",
            "Epoch 16/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6054 - accuracy: 0.8232\n",
            "Epoch 17/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5840 - accuracy: 0.8278\n",
            "Epoch 18/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6000 - accuracy: 0.8242\n",
            "Epoch 19/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5963 - accuracy: 0.8242\n",
            "Epoch 20/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5902 - accuracy: 0.8258\n",
            "Epoch 21/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5912 - accuracy: 0.8258\n",
            "Epoch 22/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.6009 - accuracy: 0.8235\n",
            "Epoch 23/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5920 - accuracy: 0.8257\n",
            "Epoch 24/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5967 - accuracy: 0.8257\n",
            "Epoch 25/25\n",
            "37630/37630 [==============================] - 98s 3ms/sample - loss: 0.5902 - accuracy: 0.8251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mmoYgAZ0YL6V",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history,string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOxPQgmyyr6E",
        "colab_type": "code",
        "outputId": "d214d913-f1e2-477b-c63c-1ac98d8ca90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plot_graphs(history,'accuracy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VOX5//H3TUgIIexElAQICKgg\nEiCiVq1La3+oVbRu4FJcsbVu1far1tZW7aKt1aq1C1q3VkW02lLFXau1LhAE2ZEdErawJJCQPffv\njxnSKWUZIIczmfm8rmuuzHnmzMx9dJjPnOec8zzm7oiIiAC0CrsAERFJHAoFERFpolAQEZEmCgUR\nEWmiUBARkSYKBRERaaJQEBGRJgoFERFpolAQEZEmrcMuYE9169bN8/Pzwy5DRKRFmTZt2np3z9nd\nei0uFPLz8ykqKgq7DBGRFsXMlseznrqPRESkiUJBRESaKBRERKSJQkFERJooFEREpIlCQUREmigU\nRESkSYu7TkFEJNHVNzSysbKWdVtqKK+qY2ttA1tr66mqbWBrbQNVdQ20bmUcelAHBvXoQLfsNmGX\n3EShICIpoba+kQ2VNazfUsv6ihpKK2oo21pLRXU9FTUNVNTUUVFTz5bqeuobnB6d2tK7axa9u2bR\nq0sWvbu2o3NWOtV1jawqr2JVWeRWUlbNqrIq1m6upnRLDesrathQWYt7/LUd2CGTw3M7MKhHR/p3\nz6bRobqugZq6BqrrGqmua6C6voFTBh5IQc9Owf1HIuBQMLORwINAGvCYu9+z3eO9gKeATtF1bnX3\nyUHWJCKJqbHRqaiNfClvqa6jtr6RzlkZdMtuQ9uMtJ0+Z9PWyC/ydVtqKI29VdRQuqW6aXlzdf0O\nX8MM2mW0JrtNa7IzI3/TWhkfLirlr5/V/Ne6memtqK5r/K+2VgbdO2TSvUMmPbtkMax3Z3Ky25DT\nPnLr1DadrIzWtM1IIyt6a5uRRnVdI3NXbWbOqnJml5QzZ9Vm3p2/jsadhElaKyO3U1bgoWC+J3G2\nJy9slgZ8AZwCFANTgTHuPjdmnfHAdHf/vZkNBCa7e/6uXrewsNA1zIVIy7VuSzUzVpQxY2UZ01eU\nsWLjVjZX1VFRW7/TX9dZGWl0zc6ga7s2dGybTlk0CEq31FC/g2/R7DatI1/K0S/nbtmRcOmaHb0f\nfaxTVjrtMlrTqpXt8H2rahso3rSV5Ru2snzjVlaXVdG5XQY9OmWS2ymLHp0iYZCe1jyHZ7fW1rN8\nw1bS04w2rdPITE8jM70Vmelp+/weZjbN3Qt3t16QewojgEXuviRa0ARgFDA3Zh0HOkTvdwRWBViP\niATE3SndUsOKjVvZUl3/nz70uobo/QYWr6tgxsoySsqqAKJ96u05qk8XOrRNp0Nma9pnptM+szUd\n2qaTntaKTZW1rK+sYUNFLRui3TKbttbSsW06/Q5oT/cObTigfRsO6JAZ+ds+k27tM8jKaJ6vtrYZ\nafTv3p7+3ds3y+vtTlZGaw47qMPuVwxQkKGQC6yMWS4GjtpunZ8Ab5rZdUA74Ks7eiEzGweMA+jV\nq1ezFyoi/2trbT1LSisj/dkx/drVdY1U1tSzcmPk1/OKDVtZsXErVXUNu3y93E5tKejVicuOzaeg\nZycOz+1IZvqOu4UkPGEfaB4DPOnuvzazY4A/m9nh7v5fnXbuPh4YD5HuoxDqFEl6myprmbpsI1OX\nbWTKsk3MKSnfYdfMNm1at2o6AHtc/2707ppFzy5ZTX3o2/rO26ZHbjvropHEEmQolAA9Y5bzom2x\nrgBGArj7x2aWCXQD1gVYl0jKq2toZMGaLcwsLmdmcRnTlm9i4boKADJat6IgrxNXn9CXw3t0pF2b\n1k1925F+7la0zUijW7s2+qJPQkGGwlSgv5n1IRIGo4ELt1tnBfAV4EkzOwzIBEoDrEkk5TQ0OktK\nK5oC4PPicuau3kxtfWSHvGPbdAp6duKsobkcmd+FI/LUrZPKAgsFd683s2uBN4icbvq4u88xs7uA\nInefBNwMPGpm3yVy0PlSD+p0KJEU0NjoLNtQyayScmYWlzOruJzZq8rZWhvp78/KSOPw3I6MPaY3\nR+R14oi8jvTqkoWZfvFLRGCnpAZFp6SKRNQ3NLJkfSWzS8qZXbI5eq57OZXRAMhMb8WgHh0ZnNuR\nI/Iif/vmZJOmLp+UlAinpIpIM9hUWcuS9ZUsXV/J0vUV0b9bWbq+oulCqsz0Vgw8qAPnDs9jUI+O\nHNGzI/1ysmndTOfPS+pQKIgkqOkrNnHv6/P5ZMnGpra0VkavLln06daOLx3clUE9OnB4bkcO1h6A\nNBOFgkiCWVxawX1vLOC12Wvo2i6Dm08ZwKDcDvTplk1e57bNdvWsyI4oFEQSxNrN1fzm7YVMLFpJ\nZutW3PjV/lx5fF+y2+ifqew/+rSJhGz+ms1MnFrMs1OW09DoXHJ0b649uV9CDacsqUOhIBKCsq21\n/H3GKl6cVsysknLS04zTBh/ETacMoHfXdmGXJylMoSCyH324cD3PTlnO23PXUdvQyMCDOvDjMwYy\nqiCXLu0ywi5PRKEgsj8sXV/JXf+Yw3sLSunSLoOLju7VdPqoSCJRKIgEqLKmnoffXcSfPlxCm9Zp\n3H7aYXzzS71p01rDSEhiUiiIBMDdmfT5Kn4+eR5rN9dwzrA8bjn1EA5onxl2aSK7pFAQaWZfrN3C\nD1+ezZRlGxmc25HfXTSc4b07h12WSFwUCiLNpKa+gUfeXcTv319Muzatuecbgzm/sKeGl5YWRaEg\n0gymLN3IrS/NZElpJWcV9OBHXx9IV11nIC2QQkFkH5RX1XHPa/N5bsoK8jq35anLR3DCgJywyxLZ\nawoFkb30r4Wl3Dzxc9ZX1HDV8X347ikDmm3CeJGw6BMssofcnd/9czG/fnMB/Q7I5k9jj2Rwnq43\nkOSgUBDZA1uq67h54ue8OXctZwzpwb3nDNbegSSVQD/NZjYSeJDIdJyPufs92z3+AHBSdDELOMDd\nOwVZk8jeWrh2C1f/eRrLN27lR18fyOXH5msaS0k6gYWCmaUBjwCnAMXAVDOb5O5zt63j7t+NWf86\nYGhQ9Yjsi1dnrub7L35OVkZrnr3yKI7q2zXskkQCEeRsHSOARe6+xN1rgQnAqF2sPwZ4LsB6RPbK\nQ+8s5DvPfsahB7bnleuOUyBIUgsyFHKBlTHLxdG2/2FmvYE+wLs7eXycmRWZWVFpaWmzFyqyMw+/\ns5D73/qCbwzLZcK4Yziwo4apkOSWKPP6jQZedPeGHT3o7uPdvdDdC3NydA647B9/eH8xv37rC74x\nNJdfnTuEjNaJ8s9FJDhBfspLgJ4xy3nRth0ZjbqOJIH86cOl3PPafM4Y0oNfnTeENA1VISkiyFCY\nCvQ3sz5mlkHki3/S9iuZ2aFAZ+DjAGsRidvTHy/j7lfmcurhB/LA+QoESS2BhYK71wPXAm8A84CJ\n7j7HzO4yszNjVh0NTHB3D6oWkXg9++kK7vj7HE4Z2J2HxgyldZq6jCS1BHqdgrtPBiZv13bHdss/\nCbIGkXhNmLKCH7w8i5MOyeG3Fw4lXYEgKUiXYkrKq65r4O5X5vLMpyv48oAcfn/xcM2MJilLoSAp\nbcWGrVzz7DRml2zmWycczPe+NkBdRpLSFAqSst6au5abJs7AgEe/WcgpA7uHXZJI6BQKknLqGhq5\n740F/PGDJdHpMofRs0tW2GWJJASFgqSU6roGLn1iCp8s2cjFR/fih6cPJDNdxw9EtlEoSEr5yaQ5\nfLJkI/edN4Rzh+eFXY5IwtERNUkZE6euZMLUlVx7Uj8FgshOKBQkJcwuKedHf5/Nsf268t1TBoRd\njkjCUihI0iuvquOaZz6jc1YGD44eqmErRHZBxxQkqTU2OjdPnMGqsiqev/oYumW3CbskkYSmPQVJ\nan/4YDFvz1vHD08/jOG9O4ddjkjCUyhI0vpo8Xrue2MBZwzpwdgv5YddjkiLoFCQpLR2czXXPzed\nvjnZ3PONwZjpOIJIPHRMQZJOfUMj1z83ncqaBp67ahjt2uhjLhIv/WuRpPPQOwv5dOlGfn3eEPp3\nbx92OSItirqPJKl8uHA9D7+3iHOH53GOLlAT2WMKBUka67ZUc+PzM+iXk81dowaFXY5IixRoKJjZ\nSDNbYGaLzOzWnaxzvpnNNbM5ZvZskPVI8mpodG6cMIOKmjoeuWgYWRnqGRXZG4H9yzGzNOAR4BSg\nGJhqZpPcfW7MOv2B24Bj3X2TmR0QVD2S3H777iI+WryBe88ZzAAdRxDZa0HuKYwAFrn7EnevBSYA\no7Zb5yrgEXffBODu6wKsR5LUx4s38OA7X3BWQQ/OL+wZdjkiLVqQoZALrIxZLo62xRoADDCzf5vZ\nJ2Y2MsB6JAmtr6jhhgnTye/ajp+eresRRPZV2B2vrYH+wIlAHvCBmQ1297LYlcxsHDAOoFevXvu7\nRklQ7s4tL86krKqOJy8bQbauRxDZZ0HuKZQAsfvyedG2WMXAJHevc/elwBdEQuK/uPt4dy9098Kc\nnJzACpaWZcLUlbwzfx23jDyUgT06hF2OSFIIMhSmAv3NrI+ZZQCjgUnbrfM3InsJmFk3It1JSwKs\nSZLEsvWV3P3KXL50cFcu07hGIs0msFBw93rgWuANYB4w0d3nmNldZnZmdLU3gA1mNhd4D/i+u28I\nqiZJDvUNjdw0cQZprYz7zhtCK82PINJsAu2EdffJwOTt2u6Iue/ATdGbSFz+8P5iPltRxoOjC+jR\nqW3Y5YgkFV3RLC3KrOJyfvP2Qr5+xEGcOaRH2OWIJB2FgrQY1XUN3Pj8dLpmZ/DTsw7X6aciAdA5\nfNJi3PPafBaXVvLnK0bQKSsj7HJEkpL2FKRF+HDhep78aBmXfimf4/vrtGSRoCgUJOFtqqzl5hdm\ncHBOO24ZeWjY5YgkNXUfSUJzd37w8iw2Vtbyp7FH0jYjLeySRJKa9hQkob0wrZjXZq/hplMO4fDc\njmGXI5L0FAqSsJatr+TOSXM4qk8Xxn25b9jliKQEhYIkpLqGRm58PnLV8gMXFJCmq5ZF9gsdU5CE\n9PC7i5ixsoyHxwzVVcsi+5H2FCThTFu+kd++u5BvDM3lDF21LLJfKRQkoWypruPG52eQ27ktd44a\nFHY5IilH3UeSUO78x1xKNlUx8epjaJ+ZHnY5IilHewqSMN6Zt5YXpxVzzYn9KMzvEnY5IilJoSAJ\noXxrHT94eRaHHtie67/yP5Pvich+ou4jSQh3vzqX9RW1PPbNI8lord8qImHRvz4J3XsL1vHitGK+\ndUJfBufpqmWRMMUVCmb2kpmdbmZ7FCJmNtLMFpjZIjO7dQePX2pmpWY2I3q7ck9eX1q+zdV13PbX\nWfQ/IFvdRiIJIN4v+d8BFwILzeweMztkd08wszTgEeBUYCAwxswG7mDV5929IHp7LN7CJTn8/NV5\nrNtSzX3nDaFNaw12JxK2uELB3d9294uAYcAy4G0z+8jMLjOznZ03OAJY5O5L3L0WmACMao6iJTl8\n8EUpE6auZNyXD2ZIz05hlyMi7MExBTPrClwKXAlMBx4kEhJv7eQpucDKmOXiaNv2zjGzmWb2opn1\njLceadm2VNdx20uzODinHTd+Vd1GIoki3mMKLwP/ArKAM9z9THd/3t2vA7L34f3/AeS7+xFEwuWp\nnbz/ODMrMrOi0tLSfXg7SRS/eG0+q8ur+NV5Q8hMV7eRSKKId0/hIXcf6O6/cPfVsQ+4e+FOnlMC\nxP7yz4u2xT53g7vXRBcfA4bv6IXcfby7F7p7YU6OpmJs6T5cuJ5nP13BFcf1YVivzmGXIyIx4g2F\ngWbW1OlrZp3N7JrdPGcq0N/M+phZBjAamBS7gpkdFLN4JjAvznqkhdpSXcctf51J35x23Py13Z6v\nICL7WbyhcJW7l21bcPdNwFW7eoK71wPXAm8Q+bKf6O5zzOwuMzszutr1ZjbHzD4HridyzEKS2M8n\nz2N1eRX3qdtIJCHFe0VzmpmZuzs0nW6asbsnuftkYPJ2bXfE3L8NuC3+cqUl++CLUp6bspKrT+ir\nbiORBBVvKLwOPG9mf4wuXx1tE4nL5mi3Ub8DsvnuVweEXY6I7ES8oXALkSD4dnT5LSIHhkXi8rNX\n5rF2czUvXXOsuo1EElhcoeDujcDvozeRPfLegnU8X7SSa048mAJdpCaS0OIKBTPrD/yCyHAVmdva\n3b1vQHVJkiivquPWv85kQPdsbtBFaiIJL96zj54gspdQD5wEPA38JaiiJHnc/UpkSGyNbSTSMsQb\nCm3d/R3A3H25u/8EOD24siQZvDlnDS9OK+bbJxzMEXnqNhJpCeI90FwTHTZ7oZldS+TK5H0Z3kKS\n3KqyKr7/4kwOz+3AdV/pF3Y5IhKnePcUbiAy7tH1RIaiuBgYG1RR0rLVNzRyw4Tp1Dc08tsxw9Rt\nJNKC7HZPIXqh2gXu/j2gArgs8KqkRXvonYVMXbaJB0cXkN+tXdjliMge2O2egrs3AMfth1okCXy0\neD0Pv7eIc4fnMapgRyOli0gii/eYwnQzmwS8AFRua3T3lwKpSlqkDRU13DhhBn26tePOMweFXY6I\n7IV4QyET2ACcHNPmgEJBAGhsdG5+4XPKqup44rIjadcm3o+WiCSSeK9o1nEE2aXH/72Ufy4o5a5R\ngxjUo2PY5YjIXor3iuYniOwZ/Bd3v7zZK5IWZ2ZxGfe+Pp+vDezOJUf3DrscEdkH8e7jvxJzPxM4\nG1jV/OVIS7O5uo5rn51OTnYbfnnuEZhZ2CWJyD6It/vor7HLZvYc8GEgFUmL4e7c9tIsSsqqmHj1\n0XTK2u0UGyKS4OK9eG17/YEDmrMQaXmem7KSV2eu5uavDWB47y5hlyMizSCuUDCzLWa2edsN+AeR\nORZ297yRZrbAzBaZ2a27WO8cM3MzK4y/dAnT/DWbufMfczi+fze+9eWDwy5HRJpJvN1H7ff0haNX\nQj8CnAIUA1PNbJK7z91uvfZEhtH4dE/fQ8Kxtbae7zzzGR3apnP/+QW0aqXjCCLJIt49hbPNrGPM\nciczO2s3TxsBLHL3Je5eC0wARu1gvbuBe4HqOGuWkP3473NYsr6S31xQQE77NmGXIyLNKN5jCj92\n9/JtC+5eBvx4N8/JBVbGLBdH25qY2TCgp7u/GmcdErKXPivmhWnFXHdSP47t1y3sckSkmcUbCjta\nb58uWY0OxX0/cHMc644zsyIzKyotLd2Xt5V9sLi0gh/+bTYj8rtw/Vc0i5pIMoo3FIrM7H4zOzh6\nux+YtpvnlAA9Y5bzom3btAcOB/5pZsuAo4FJOzrY7O7j3b3Q3QtzcnLiLFmaU2VNPdf85TPatG7F\ng2MKaJ22tyeuiUgii/df9nVALfA8kWMD1cB3dvOcqUB/M+tjZhnAaGDStgfdvdzdu7l7vrvnA58A\nZ7p70R5ugwTM3fneC5+zcN0WHhw9lIM6tg27JBEJSLxnH1UCOz2ldCfPqY/O0vYGkAY87u5zzOwu\noMjdJ+36FSRR/PbdRbw2ew23n3YYXx6gPTWRZBbv2EdvAedFDzBjZp2BCe7+/3b1PHefDEzeru2O\nnax7Yjy1yP719ty1/PqtLzh7aC5XHt8n7HJEJGDxdh912xYIAO6+CV3RnPQWravgxudnMDi3I7/4\nxmCNaySSAuINhUYz67Vtwczy2cGoqZI8yqvqGPd0EZnprfjjJcPJTNc8yyKpIN7TSm8HPjSz9wED\njgfGBVaVhKqh0blxwnRWbNzKs1cdTY9OOrAskiriPdD8evRU0XHAdOBvQFWQhUl47ntzAe8tKOWn\nZx3OiD4a6E4klcR7oPlKIuMT5QEziFxT8DH/PT2nJIGnPlrG7/+5mAuP6sXFmjBHJOXEe0zhBuBI\nYLm7nwQMBcp2/RRpaf42vYQfT5rD1wZ2564zB4VdjoiEIN5QqHb3agAza+Pu84FDgitL9rd356/l\n5hc+55i+XXlozFBdsSySouI90FxsZp2IHEt4y8w2AcuDK0v2pylLN/Ltv3zGoB4deHRsoc40Eklh\n8R5oPjt69ydm9h7QEXg9sKpkv5ldUs4VT04lr3NbnrxsBNlt9mmcQxFp4fb4G8Dd3w+iENn/lpRW\nMPbxKbTPbM2frziKLu00x7JIqlPHcYoqKavikj9NAeDPVx6laxFEBNjHORGkZVpdXsWY8Z+wubqO\n5646moNzssMuSUQShPYUUszazdWMGf8Jmypr+fMVR3F4bsfdP0lEUoZCIYWs2xIJhNItNTx5+QgK\nenYKuyQRSTDqPkoR6ytquPDRT1mzuZqnLh/B8N6dwy5JRBKQ9hRSwIaKGi569FOKN23l8UuP5Mh8\njWckIjumUEhyZVtrueixT1m2oZLHxx7J0X27hl2SiCSwQEPBzEaa2QIzW2Rm/zOdp5l9y8xmmdkM\nM/vQzAYGWU+qqaipZ+wTU1myvpLHxhbypX7dwi5JRBJcYKFgZmnAI8CpwEBgzA6+9J9198HuXgD8\nErg/qHpSTXVdA1c9VcTsknIeuXAYx/fX3MoisntB7imMABa5+xJ3rwUmAKNiV3D3zTGL7dBsbs2i\nrqGR656bzsdLNnDfeUdwysDuYZckIi1EkGcf5QIrY5aLgaO2X8nMvgPcBGSg+Rn2WWOj838vzuSt\nuWu5a9Qgzh6aF3ZJItKChH6g2d0fcfeDgVuAH+5oHTMbZ2ZFZlZUWlq6fwtsQdydO/8xh5enl/C9\nrw3gm8fkh12SiLQwQYZCCdAzZjkv2rYzE4CzdvSAu49390J3L8zJUd/4ztz/1hc89fFyxn25L985\nqV/Y5YhICxRkKEwF+ptZHzPLAEYDk2JXMLP+MYunAwsDrCepPf7hUh5+dxGjj+zJbaceipmFXZKI\ntECBHVNw93ozuxZ4A0gDHnf3OWZ2F1Dk7pOAa83sq0AdsAkYG1Q9yey1Wau5+9W5jBx0ID87e7AC\nQUT2WqDDXLj7ZGDydm13xNy/Icj3TwXTlm/kxudnMLRnJ34zuoC0VgoEEdl7oR9olr23dH0lVz5V\nxEEdM3ls7JGaRlNE9plCoYXaUFHDZU9Mwcx48rIRmjVNRJqFQqEFqq5r4Mqni1hdXs1jYwvJ79Yu\n7JJEJElo6OwWpqHRuWHCdGasLOP3Fw1nWC8NgS0izUd7Ci3Mz16dxxtz1vKj0wcy8vADwy5HRJKM\nQqEFeexfS3j830u57Nh8Lj+uT9jliEgSUii0EK/OXM3PJs/jtMEH8qPTNcK4iARDodACTFm6ke9O\nnMHwXp25//wCWulaBBEJiEIhwS1at4Wrni4ir3NbHv1moa5FEJFAKRQS2LrN1Yx9fCrpaa146rIR\ndNa1CCISMIVCgqqoqefyp6ayaWstT1x6JD27ZIVdkoikAF2nkIBq6xu55pnPmLd6C4+NLWRwXsew\nSxKRFKE9hQRT39DI9c9N54MvSvnF2YM56ZADwi5JRFKIQiGBNDQ6N7/wOa/PWcMdXx/I+Uf23P2T\nRESakUIhQTQ2Ore/PIu/z1jF/408RBeniUgoFAoJwN2565W5TJi6kutO7sc1J2oqTREJh0IhZO7O\nPa/P58mPlnHlcX246ZQBYZckIiks0FAws5FmtsDMFpnZrTt4/CYzm2tmM83sHTPrHWQ9ieihdxbx\nx/eXcNFRvbj99MM0laaIhCqwUDCzNOAR4FRgIDDGzLYftGc6UOjuRwAvAr8Mqp5E9PcZJTzw9hec\nMyyPu0cdrkAQkdAFuacwAljk7kvcvRaYAIyKXcHd33P3rdHFT4C8AOtJKMs3VHL7y7Mp7N2Ze88Z\nrPGMRCQhBBkKucDKmOXiaNvOXAG8FmA9CaO2vpHrnptOK4MHxwyldZoO7YhIYkiIK5rN7GKgEDhh\nJ4+PA8YB9OrVaz9WFoxfvTGfmcXl/OHi4eR2aht2OSIiTYL8iVoCxF59lRdt+y9m9lXgduBMd6/Z\n0Qu5+3h3L3T3wpycnECK3V/eW7COR/+1lEuO7q2Z00Qk4QQZClOB/mbWx8wygNHApNgVzGwo8Eci\ngbAuwFoSwtrN1dw88XMOPbA9t59+WNjliIj8j8BCwd3rgWuBN4B5wER3n2Nmd5nZmdHVfgVkAy+Y\n2Qwzm7STl2vxGhqd7z4/g6raBn574VDNiyAiCSnQYwruPhmYvF3bHTH3vxrk+yeSP7y/mI8Wb+CX\n5xxBvwPah12OiMgO6bSX/WDK0o3c/9YXnDGkB+cVpsxZtyLSAikUAlZSVsU1z0yjV5csfna2LlAT\nkcSWEKekJquq2gbGPV1EdV0jE8YNp0NmetgliYjskkIhIO7O91/8nLmrN/OnsYU6jiAiLYK6jwLy\nu38u5pWZq/n+/zuEkw/tHnY5IiJxUSgE4J15a7nvzQWcOaQH3z7h4LDLERGJm0KhmS1at4UbJsxg\nUI8O3HvOETqwLCItikKhGZVvrePKp4rITE9j/CWFtM3QBWoi0rIoFJrJ1tp6rnq6iJKyKv5w8TB6\naKA7EWmBFArNoKq2gcufnErR8o38+vwCCvO7hF2SiMhe0Smp+6i6roGrni7i06UbeeD8As4c0iPs\nkkRE9pr2FPZBdV0D4/48jX8vXs+vzh3CWUN3NYeQiEjiUyjspZr6Bq555jM++KKUe74xmHOHa0wj\nEWn5FAp7oba+ke88M51356/j52cP5oIjW/5scCIioFDYY3UNjVz/3HTenreWu0cN4sKjFAgikjwU\nCnugrqGR656dzutz1vDjMwZyyTH5YZckItKsFApx2raH8PqcNdzx9YFcdmyfsEsSEWl2gYaCmY00\nswVmtsjMbt3B4182s8/MrN7Mzg2yln1R19DIDROm89rsSCBcfpwCQUSSU2ChYGZpwCPAqcBAYIyZ\nDdxutRXApcCzQdWxr7YFwuRZa/iRAkFEklyQF6+NABa5+xIAM5sAjALmblvB3ZdFH2sMsI69VtfQ\nyI0TZjB51hp+ePphXKFAEJEkF2T3US6wMma5ONrWIjQ0Ojc+P4NXZ63mh6cfxpXH9w27JBGRwLWI\nA81mNs7MisysqLS0dL+8509fncurM1fzg9MOVSCISMoIMhRKgJ4xy3nRtj3m7uPdvdDdC3Nycpql\nuF15/MOlPPHvZVx5XB/GfVnH00H0AAAG/0lEQVST5IhI6ggyFKYC/c2sj5llAKOBSQG+X7N4c84a\n7n51LiMHHcgPTjss7HJERParwELB3euBa4E3gHnARHefY2Z3mdmZAGZ2pJkVA+cBfzSzOUHVE48Z\nK8u4fsJ0huR14oELCmjVSrOmiUhqCXTobHefDEzeru2OmPtTiXQrhW7lxq1c+dRUctq34bGxmjVN\nRFKT5lMgMo3mpU9Moa7BmXDpCLpltwm7JBGRULSIs4+CtKW6jqv/UsTKjVWMv2Q4/Q7IDrskEZHQ\npOyeQmOj8+K0Yn75xgI2VNbwwPkFHNW3a9hliYiEKiVDoWjZRu78x1xmlZQztFcnHhtbSEHPTmGX\nJSISupQKhVVlVdzz2nwmfb6KAztk8psLChhV0AMznWUkIgIpFAoTp67kjkmzcYfrT+7Ht048mKyM\nlNl8EZG4pMy3Yn63dnzl0O7cdtqh5HXOCrscEZGElDKhMKJPF0b06RJ2GSIiCS3lT0kVEZH/UCiI\niEgThYKIiDRRKIiISBOFgoiINFEoiIhIE4WCiIg0USiIiEgTc/ewa9gjZlYKLN/Lp3cD1jdjOS1F\nqm43pO62a7tTSzzb3dvddzvJfYsLhX1hZkXuXhh2Hftbqm43pO62a7tTS3Nut7qPRESkiUJBRESa\npFoojA+7gJCk6nZD6m67tju1NNt2p9QxBRER2bVU21MQEZFdSJlQMLORZrbAzBaZ2a1h1xMUM3vc\nzNaZ2eyYti5m9paZLYz+7RxmjUEws55m9p6ZzTWzOWZ2Q7Q9qbfdzDLNbIqZfR7d7juj7X3M7NPo\n5/15M8sIu9YgmFmamU03s1eiy0m/3Wa2zMxmmdkMMyuKtjXb5zwlQsHM0oBHgFOBgcAYMxsYblWB\neRIYuV3brcA77t4feCe6nGzqgZvdfSBwNPCd6P/jZN/2GuBkdx8CFAAjzexo4F7gAXfvB2wCrgix\nxiDdAMyLWU6V7T7J3QtiTkNtts95SoQCMAJY5O5L3L0WmACMCrmmQLj7B8DG7ZpHAU9F7z8FnLVf\ni9oP3H21u38Wvb+FyBdFLkm+7R5REV1Mj94cOBl4MdqedNsNYGZ5wOnAY9FlIwW2eyea7XOeKqGQ\nC6yMWS6OtqWK7u6+Onp/DdA9zGKCZmb5wFDgU1Jg26NdKDOAdcBbwGKgzN3ro6sk6+f9N8D/AY3R\n5a6kxnY78KaZTTOzcdG2Zvucp8wczRLh7m5mSXvKmZllA38FbnT3zZEfjxHJuu3u3gAUmFkn4GXg\n0JBLCpyZfR1Y5+7TzOzEsOvZz45z9xIzOwB4y8zmxz64r5/zVNlTKAF6xiznRdtSxVozOwgg+ndd\nyPUEwszSiQTCM+7+UrQ5JbYdwN3LgPeAY4BOZrbtR18yft6PBc40s2VEuoNPBh4k+bcbdy+J/l1H\n5EfACJrxc54qoTAV6B89MyEDGA1MCrmm/WkSMDZ6fyzw9xBrCUS0P/lPwDx3vz/moaTedjPLie4h\nYGZtgVOIHE95Dzg3ulrSbbe73+buee6eT+Tf87vufhFJvt1m1s7M2m+7D3wNmE0zfs5T5uI1MzuN\nSB9kGvC4u/8s5JICYWbPAScSGTVxLfBj4G/ARKAXkRFmz3f37Q9Gt2hmdhzwL2AW/+lj/gGR4wpJ\nu+1mdgSRA4tpRH7kTXT3u8ysL5Ff0F2A6cDF7l4TXqXBiXYffc/dv57s2x3dvpeji62BZ939Z2bW\nlWb6nKdMKIiIyO6lSveRiIjEQaEgIiJNFAoiItJEoSAiIk0UCiIi0kShIBJlZg3RkSe33Zpt8Dwz\ny48duVYkUWmYC5H/qHL3grCLEAmT9hREdiM6fv0vo2PYTzGzftH2fDN718xmmtk7ZtYr2t7dzF6O\nznHwuZl9KfpSaWb2aHTegzejVyBjZtdH54GYaWYTQtpMEUChIBKr7XbdRxfEPFbu7oOB3xK5Mh7g\nYeApdz8CeAZ4KNr+EPB+dI6DYcCcaHt/4BF3HwSUAedE228FhkZf51tBbZxIPHRFs0iUmVW4e/YO\n2pcRmchmSXTQvTXu3tXM1gMHuXtdtH21u3czs1IgL3Z4hehw3m9FJ0HBzG4B0t39p2b2OlBBZDiS\nv8XMjyCy32lPQSQ+vpP7eyJ2DJ4G/nNM73QiMwMOA6bGjPIpst8pFETic0HM34+j9z8iMkInwEVE\nBuSDyHSI34amCXA67uxFzawV0NPd3wNuAToC/7O3IrK/6BeJyH+0jc5gts3r7r7ttNTOZjaTyK/9\nMdG264AnzOz7QClwWbT9BmC8mV1BZI/g28BqdiwN+Es0OAx4KDovgkgodExBZDeixxQK3X192LWI\nBE3dRyIi0kR7CiIi0kR7CiIi0kShICIiTRQKIiLSRKEgIiJNFAoiItJEoSAiIk3+P+sb87XUHZbH\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dRpO8xpG1vs",
        "colab_type": "text"
      },
      "source": [
        "## **Predict using the trained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7UpCAhBsLbT",
        "colab_type": "text"
      },
      "source": [
        "Its time to predict the next sequence of words. Here lets assume that the seed text to be \"We loved\". Lets see what our model predicts the next 200 words to be. \n",
        "\n",
        "The seed text is preprocessed, padded and used as the input to predict the next word. Once predicted its concatenated to the original seed text and the next prediction is made. This sequence is repeated for 200 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFA1XFW_gXJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songsByArtist = songsByArtist.reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIaIHjj6YQxc",
        "colab_type": "code",
        "outputId": "fa954251-8041-4a59-db6b-faca3972e878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "minLengthOfASong = int(np.min([len(songsByArtist[\"text\"][key].split(\"\\n\")) for key in range(songsByArtist.shape[0])]))\n",
        "print(\"Min Length of a Song :\",minLengthOfASong,' lines')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min Length of a Song : 17  lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efk3QGJWZ3Bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allSongDataByArtist = [songsByArtist[\"text\"][key].split(\"\\n\") for key in range(songsByArtist.shape[0])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5-YbNk5g8JT",
        "colab_type": "code",
        "outputId": "f2851e90-c44b-4a1d-daa3-d10d360cf47c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wordsByLines = []\n",
        "for loop1 in range(len(allSongDataByArtist)):\n",
        "  for loop2 in range(minLengthOfASong):\n",
        "    if (loop1 == 0):\n",
        "      wordsByLines.append(len([elem.strip() for elem in allSongDataByArtist[loop1][loop2].split(\" \") if elem.strip()!=\"\"]))\n",
        "    else:\n",
        "      wordsByLines[loop2] = (wordsByLines[loop2]+len([elem.strip() for elem in allSongDataByArtist[loop1][loop2].split(\" \") if elem.strip()!=\"\"]))/2\n",
        "wordsInTotal = int(sum(wordsByLines))\n",
        "print(\"Average number of words per song :\",wordsInTotal)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average number of words per song : 105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmDNlSZnrCWF",
        "colab_type": "code",
        "outputId": "80b87ece-7ccf-4af0-a4c7-862ab76312ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seed_text = \"We loved\"\n",
        "next_words = wordsInTotal\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_len_sequence-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We loved what she can just make it to the morning to end up for gold from the great beyond the other side of your leash light where the dry shells down' i threw away and politely down' i threw over the tall cornfields clouds a few lights stranger to see mouse's door flows to stone her and rapes her working in the chapel after darlin' we won't look hard opens me to this time and hard and bad at night and dry brush'll whole world down apart to fight put me off the seat and slept he awoke off the tribes of the road light dinah\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXLK6STHKkki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newSong = [elem for elem in seed_text.split(\" \")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vSr-JSjlNj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordsByLines = [int(elem) for elem in wordsByLines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYSNjKNXlsAQ",
        "colab_type": "code",
        "outputId": "10cf67d9-f21b-4c2a-df53-9d90dd9e4512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "startPos = 0\n",
        "endPos = 0\n",
        "for loop in range(len(wordsByLines)):\n",
        "  endPos = endPos + wordsByLines[loop]\n",
        "  print(' '.join(elem for elem in newSong[startPos:endPos]))\n",
        "  startPos = endPos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We loved what she can just make it\n",
            "to the morning to end up for gold\n",
            "from the great beyond the other side of\n",
            "your leash light where the dry shells\n",
            "down' i\n",
            "threw away and politely\n",
            "down' i threw\n",
            "over the tall cornfields clouds a few\n",
            "lights stranger to see mouse's\n",
            "door flows to stone her and rapes\n",
            "her working in the chapel after darlin'\n",
            "we won't look hard opens me\n",
            "to this time and\n",
            "hard and bad\n",
            "at night and dry brush'll whole world\n",
            "down apart to fight\n",
            "put me off the seat\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}