{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "deepNeuralNetworks_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datasigntist/deeplearning/blob/master/deepNeuralNetworks_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8wXanm0882b",
        "colab_type": "text"
      },
      "source": [
        "**Author**: Vishwanathan Raman\n",
        "**Email**: datasigntist@gmail.com\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Change History**\n",
        "\n",
        "\n",
        "*   1-Jan-2018 -- Initial Creation\n",
        "*   14-Aug-2019 -- Included detailed comments for each step\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Credits**\n",
        "The code articulated here has been inspired from coursera deeplearning.ai Assignments\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Use Case Description**\n",
        "\n",
        "This notebook develops a Deep Neural Network to solve the Classification problem using Logistic Regression. A Deep Neural Network has multiple layers having multiple nodes through which input is processed.The dataset (.h5) is a collection of Cat Images. The data files needs to be uploaded to the Files section in the colab environment.  The library  h5py package (https://www.h5py.org/) is a Pythonic interface to the HDF5 binary data format. Each Image is a collection of R,G,B pixel intensity values represented as matrices, also called channels. The pixel intensity values are the features that defines the Image. Each Image is represented as a single vector of pixel intensity values.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Train dataset : https://github.com/datasigntist/datasetsForTraining/blob/master/train_catvnoncat.h5\n",
        "*   Test dataset  : https://github.com/datasigntist/datasetsForTraining/blob/master/test_catvnoncat.h5\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Other Learning Resources**\n",
        "\n",
        "The following youtube playlist lists all the concepts related to Deep Learning \n",
        "\n",
        "https://www.youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0\n",
        "\n",
        "https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoIn6PNQAk6y",
        "colab_type": "text"
      },
      "source": [
        "The following represents a 3 layer neural network representation having 2 hidden layers and 1 output layer.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Neural%20Network%20Representation.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXWE8u3q86A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the libraries\n",
        "import time\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8KAvzPP8d7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(Z):\n",
        "    \"\"\"\n",
        "    Implements the sigmoid activation in numpy\n",
        "    \n",
        "    Arguments:\n",
        "    Z -- numpy array of any shape\n",
        "    \n",
        "    Returns:\n",
        "    A -- output of sigmoid(z), same shape as Z\n",
        "    cache -- returns Z as well, useful during backpropagation\n",
        "    \"\"\"\n",
        "    \n",
        "    A = 1/(1+np.exp(-Z))\n",
        "    cache = Z\n",
        "    \n",
        "    return A, cache\n",
        "\n",
        "def sigmoid_backward(dA, cache):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation for a single SIGMOID unit.\n",
        "\n",
        "    Arguments:\n",
        "    dA -- post-activation gradient, of any shape\n",
        "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
        "\n",
        "    Returns:\n",
        "    dZ -- Gradient of the cost with respect to Z\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = cache\n",
        "    \n",
        "    s = 1/(1+np.exp(-Z))\n",
        "    dZ = dA * s * (1-s)\n",
        "    \n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "    \n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iVJN-F48d7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data\n",
        "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1IRa14D8d7v",
        "colab_type": "code",
        "outputId": "387f0335-3dea-49a2-dd6a-2742f86dedce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Example of a picture\n",
        "index = 10\n",
        "plt.imshow(train_x_orig[index])\n",
        "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y = 0. It's a non-cat picture.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTNQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAAqX_fD8d70",
        "colab_type": "code",
        "outputId": "67a23f40-49c6-475a-c62e-ba5348ee02c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Explore your dataset \n",
        "# Number of training examples\n",
        "m_train = train_x_orig.shape[0]\n",
        "# Size of the image in pixels\n",
        "num_px = train_x_orig.shape[1]\n",
        "# Number of test examples\n",
        "m_test = test_x_orig.shape[0]\n",
        "\n",
        "print (\"Number of training examples: \" + str(m_train))\n",
        "print (\"Number of testing examples: \" + str(m_test))\n",
        "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
        "print (\"train_y shape: \" + str(train_y.shape))\n",
        "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
        "print (\"test_y shape: \" + str(test_y.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 209\n",
            "Number of testing examples: 50\n",
            "Each image is of size: (64, 64, 3)\n",
            "train_x_orig shape: (209, 64, 64, 3)\n",
            "train_y shape: (1, 209)\n",
            "test_x_orig shape: (50, 64, 64, 3)\n",
            "test_y shape: (1, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKnRhVQq8d73",
        "colab_type": "code",
        "outputId": "8ba13d56-118f-46c1-9aa1-332b0eebc673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Reshape the training and test examples \n",
        "# The \"-1\" makes reshape flatten the remaining dimensions\n",
        "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   \n",
        "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
        "\n",
        "# Standardize data to have feature values between 0 and 1.\n",
        "train_x = train_x_flatten/255.\n",
        "test_x = test_x_flatten/255.\n",
        "\n",
        "print (\"train_x's shape: \" + str(train_x.shape))\n",
        "print (\"test_x's shape: \" + str(test_x.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x's shape: (12288, 209)\n",
            "test_x's shape: (12288, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDRvMJfIGme",
        "colab_type": "text"
      },
      "source": [
        "initialize_param_deep_nn is a function that outlines the layers within the neural network. Each layer has a collection of nodes and each node has a linear and an activation component. Each layer has its own set of parameters W and b. The function initializes W to a set of random values.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Layer%20Definition%20and%20Initialization.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jlz0wX1a8d75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_param_deep_nn(layer_dims):\n",
        "    \"\"\"\n",
        "        layer_dims defines the number of nodes in each layer starting from the input to the output\n",
        "        \n",
        "        Each layer (minus the input layer) has 2 parameters\n",
        "            W : The Weights has a shape of (n[l],n[l-1]), its initialized to random values\n",
        "            b : The bias is a vector of real numbers. Its of shape (n[l],1), its initialized to all 0s\n",
        "    \"\"\"\n",
        "    \n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "    \n",
        "    for l in range(1,L):\n",
        "        parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1]) / np.sqrt(layer_dims[l-1])\n",
        "        parameters[\"b\" + str(l)] = np.zeros((layer_dims[l],1))\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IwpWKz78d77",
        "colab_type": "code",
        "outputId": "afeaf2bf-bf54-4520-ca5c-c9b40e8da12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Create a 3 layer neural network having \n",
        "# 12288 features in the input layer\n",
        "# 2 hidden layers\n",
        "# The 1st hidden layer has 2 nodes\n",
        "# The 2nd hidden layer has 3 nodes\n",
        "# 1 output node since we are solving the problem of binary classification\n",
        "\n",
        "layer_dims = [train_x.shape[0],2,3,1]\n",
        "parameters = initialize_param_deep_nn(layer_dims)\n",
        "\n",
        "L = len(layer_dims)\n",
        "for l in range(1,L):\n",
        "    print(\"shape of W\"+str(l)+\" is \"+str(parameters[\"W\"+str(l)].shape))\n",
        "    print(\"shape of b\"+str(l)+\" is \"+str(parameters[\"b\"+str(l)].shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of W1 is (2, 12288)\n",
            "shape of b1 is (2, 1)\n",
            "shape of W2 is (3, 2)\n",
            "shape of b2 is (3, 1)\n",
            "shape of W3 is (1, 3)\n",
            "shape of b3 is (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hu2kBXna-ge",
        "colab_type": "text"
      },
      "source": [
        "A representation of forward and backward computation across the layers\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Forward%20and%20Backward%20Computation.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KZiTbN18d7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Develop the forward propagation\n",
        "# linear_forward \n",
        "# linear_activation_forward\n",
        "# L_model_forward\n",
        "def linear_forward(A, W, b):\n",
        "    \"\"\"\n",
        "        A_prev : the input layer\n",
        "        W and b : the parameters\n",
        "        Z : the output of the linear function\n",
        "        cache the values of A, W, b, this will be used during backward propagation\n",
        "    \"\"\"\n",
        "    \n",
        "    Z = np.dot(W, A) + b\n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGeqnAY08d8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_forward(A, W, b, activation):\n",
        "    \"\"\"\n",
        "        Calls the linear_forward for applying the linear function\n",
        "        Applies activation on top of the linear function, here activation is passed as a string\n",
        "    \"\"\"\n",
        "    \n",
        "    if activation == \"sigmoid\":\n",
        "        Z, linear_cache = linear_forward(A, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "        \n",
        "    cache = (linear_cache, activation_cache)  \n",
        "        \n",
        "    return A, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iJSXZbK8d8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_forward(X, parameters):\n",
        "    \"\"\"\n",
        "        Does the forward propagation across the layers\n",
        "        \n",
        "        The final output is defined as AL\n",
        "    \"\"\"\n",
        "    \n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters)//2\n",
        "    \n",
        "    # The loop executes the forward propagation across the layer. Each layer outputs A which is passed as an input\n",
        "    # to the next layer. The input to the first layer is the input X\n",
        "    for l in range(1,L):\n",
        "        A_prev = A\n",
        "        A, cache = linear_activation_forward(A_prev, parameters[\"W\"+str(l)], parameters[\"b\"+str(l)], \"sigmoid\")\n",
        "        caches.append(cache)\n",
        "        \n",
        "    AL, cache = linear_activation_forward(A, parameters[\"W\"+str(L)], parameters[\"b\"+str(L)], \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "        \n",
        "    return AL, caches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDlYJ1qo8d8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(AL, Y):\n",
        "    \"\"\"\n",
        "        In the current scenario, the sigmoid function is used in the final output layer\n",
        "    \"\"\"\n",
        "    \n",
        "    m = Y.shape[1] \n",
        "    cost = (1./m) * (-np.dot(Y,np.log(AL).T) - np.dot(1-Y, np.log(1-AL).T))\n",
        "    \n",
        "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYeVztlFv03v",
        "colab_type": "text"
      },
      "source": [
        "Backward Computation Illustration -- Representative Steps for a Logistic Regression\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Backward%20Computation%20--%201.png)\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Backward%20Computation%20--%202.png)\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Backward%20Computation%20--%203.png)\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Backward%20Computation%20--%204.png)\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/datasigntist/imagesforNotebook/master/Backward%20Computation%20--%205.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dM1pP-Z8d8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Develop the backward propagation\n",
        "# linear_backward \n",
        "# linear_activation_backward\n",
        "# L_model_backward\n",
        "def linear_backward(dZ, cache):\n",
        "    \"\"\"\n",
        "        calculates the following\n",
        "        dW, db, dA\n",
        "    \"\"\"\n",
        "    \n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "    \n",
        "    dW = 1./m*np.dot(dZ, A_prev.T)\n",
        "    db = 1./m*np.sum(dZ, axis = 1, keepdims = True)\n",
        "    dA_prev = np.dot(W.T, dZ)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNur7zj58d8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    \"\"\"\n",
        "        calculates the following\n",
        "        dZ\n",
        "    \"\"\"\n",
        "    \n",
        "    linear_cache, activation_cache = cache\n",
        "    \n",
        "    if activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw00WJuY8d8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    \"\"\"\n",
        "    Implement the backward propagation \n",
        "    \n",
        "    Arguments:\n",
        "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
        "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
        "    caches -- list of caches containing:\n",
        "                every cache of linear_activation_forward() with \"relu\" (there are (L-1) or them, indexes from 0 to L-2)\n",
        "                the cache of linear_activation_forward() with \"sigmoid\" (there is one, index L-1)\n",
        "    \n",
        "    Returns:\n",
        "    grads -- A dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ... \n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ... \n",
        "    \"\"\"\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "    \n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"sigmoid\")\n",
        "    \n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation = \"sigmoid\")\n",
        "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "\n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE_SClMs8d8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \"\"\"\n",
        "    Update parameters using gradient descent\n",
        "    \n",
        "    Arguments:\n",
        "    parameters -- python dictionary containing your parameters \n",
        "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python dictionary containing your updated parameters \n",
        "                  parameters[\"W\" + str(l)] = ... \n",
        "                  parameters[\"b\" + str(l)] = ...\n",
        "    \"\"\"\n",
        "    \n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    # Update rule for each parameter. Use a for loop.\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdwOjzR58d8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
        "    \"\"\"\n",
        "    Implements a L-layer neural network: .\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
        "    learning_rate -- learning rate of the gradient descent update rule\n",
        "    num_iterations -- number of iterations of the optimization loop\n",
        "    print_cost -- if True, it prints the cost every 100 steps\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "    costs = []                         # keep track of cost\n",
        "    \n",
        "    # Parameters initialization.\n",
        "    parameters = initialize_param_deep_nn(layers_dims)\n",
        "    \n",
        "    # Loop (gradient descent)\n",
        "    for i in range(0, num_iterations):\n",
        "        \n",
        "        AL, caches = L_model_forward(X, parameters)\n",
        "        \n",
        "        # Compute cost.\n",
        "        cost = compute_cost(AL, Y)\n",
        "    \n",
        "        # Backward propagation.\n",
        "        grads = L_model_backward(AL, Y, caches)\n",
        " \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "                \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        if print_cost and i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per tens)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJInApBU8d8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers_dims = [12288, 2, 1,1] #  2-layer model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck6Q4WjD8d8b",
        "colab_type": "code",
        "outputId": "dacb0bd9-d784-460c-8ea5-864f1f8946d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "source": [
        "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 0.746862\n",
            "Cost after iteration 100: 0.707051\n",
            "Cost after iteration 200: 0.684073\n",
            "Cost after iteration 300: 0.669829\n",
            "Cost after iteration 400: 0.660811\n",
            "Cost after iteration 500: 0.655025\n",
            "Cost after iteration 600: 0.651274\n",
            "Cost after iteration 700: 0.648824\n",
            "Cost after iteration 800: 0.647211\n",
            "Cost after iteration 900: 0.646144\n",
            "Cost after iteration 1000: 0.645435\n",
            "Cost after iteration 1100: 0.644961\n",
            "Cost after iteration 1200: 0.644644\n",
            "Cost after iteration 1300: 0.644430\n",
            "Cost after iteration 1400: 0.644286\n",
            "Cost after iteration 1500: 0.644189\n",
            "Cost after iteration 1600: 0.644122\n",
            "Cost after iteration 1700: 0.644077\n",
            "Cost after iteration 1800: 0.644046\n",
            "Cost after iteration 1900: 0.644024\n",
            "Cost after iteration 2000: 0.644009\n",
            "Cost after iteration 2100: 0.643998\n",
            "Cost after iteration 2200: 0.643990\n",
            "Cost after iteration 2300: 0.643984\n",
            "Cost after iteration 2400: 0.643979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAEWCAYAAAA5Am/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svzirCb58d8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "    \"\"\"\n",
        "    This function is used to predict the results of a  L-layer neural network.\n",
        "    \n",
        "    Arguments:\n",
        "    X -- data set of examples you would like to label\n",
        "    parameters -- parameters of the trained model\n",
        "    \n",
        "    Returns:\n",
        "    p -- predictions for the given dataset X\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]\n",
        "    n = len(parameters) // 2 # number of layers in the neural network\n",
        "    p = np.zeros((1,m))\n",
        "    \n",
        "    # Forward propagation\n",
        "    probas, caches = L_model_forward(X, parameters)\n",
        "\n",
        "    \n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, probas.shape[1]):\n",
        "        if probas[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "    \n",
        "    #print results\n",
        "    #print (\"predictions: \" + str(p))\n",
        "    #print (\"true labels: \" + str(y))\n",
        "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
        "        \n",
        "    return p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cU_Z7VO8d8l",
        "colab_type": "code",
        "outputId": "cbca0f2c-cfad-4034-e564-b1ed6cf9fe40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_train = predict(train_x, train_y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6555023923444976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtxCDAn38d8q",
        "colab_type": "code",
        "outputId": "c1b5f988-54d4-458b-c002-8b4160494ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_test = predict(test_x, test_y, parameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3400000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRHM5Lp0dmg-",
        "colab_type": "text"
      },
      "source": [
        "As next steps, \n",
        "*   You can experiment with different hyper parameters\n",
        "        *  Experiment with new neural network architectures (hidden layers, nodes per hidden layer)\n",
        "        *  Adjust the number of iterations\n",
        "        *  Use the ReLU in the hidden layers instead of Sigmoid"
      ]
    }
  ]
}